
\documentclass[a4paper,12pt]{article}

\usepackage{fancyhdr}
\usepackage{amssymb}
%\usepackage{mathpazo}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{slashed}
\usepackage{cancel}
\usepackage[mathscr]{euscript}

\newcommand{\tab}{\hspace{4mm}} %Spacing aliases
\newcommand{\shunt}{\vspace{20mm}}

\newcommand{\sd}{\partial} %Squiggle d

\newcommand{\absval}[1]{\left\lvert #1 \right\rvert}
\newcommand{\norm}[1]{\|#1\|}
\newcommand{\anbrack}[1]{\left\langle #1 \right\rangle}



\newcommand{\al}{\alpha} %Steal ALL of Dr. Kable's Aliases! MWAHAHAHAHA!
\newcommand{\be}{\beta}
\newcommand{\ga}{\gamma}
\newcommand{\Ga}{\Gamma}
\newcommand{\de}{\delta}
\newcommand{\De}{\Delta}
\newcommand{\ep}{\epsilon}
\newcommand{\vep}{\varepsilon}
\newcommand{\ze}{\zeta}
\newcommand{\et}{\eta}
\newcommand{\tha}{\theta}
\newcommand{\vtha}{\vartheta}
\newcommand{\Tha}{\Theta}
\newcommand{\io}{\iota}
\newcommand{\ka}{\kappa}
\newcommand{\la}{\lambda}
\newcommand{\La}{\Lambda}
\newcommand{\rh}{\rho}
\newcommand{\si}{\sigma}
\newcommand{\Si}{\Sigma}
\newcommand{\ta}{\tau}
\newcommand{\ups}{\upsilon}
\newcommand{\Ups}{\Upsilon}
\newcommand{\ph}{\phi}
\newcommand{\Ph}{\Phi}
\newcommand{\vph}{\varphi}
\newcommand{\vpi}{\varpi}
\newcommand{\ch}{\chi}
\newcommand{\ps}{\psi}
\newcommand{\Ps}{\Psi}
\newcommand{\om}{\omega}
\newcommand{\Om}{\Omega}

\newcommand{\bbA}{\mathbb{A}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\bbB}{\mathbb{B}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\bbD}{\mathbb{D}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbG}{\mathbb{G}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\bbH}{\mathbb{H}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\bbJ}{\mathbb{J}}
\newcommand{\bbK}{\mathbb{K}}
\newcommand{\bbL}{\mathbb{L}}
\newcommand{\bbM}{\mathbb{M}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\bbO}{\mathbb{O}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\bbT}{\mathbb{T}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbV}{\mathbb{V}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbY}{\mathbb{Y}}
\newcommand{\bbZ}{\mathbb{Z}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand{\scrA}{\mathcal{A}}
\newcommand{\scrB}{\mathcal{B}}
\newcommand{\scrC}{\mathcal{C}}
\newcommand{\scrD}{\mathcal{D}}
\newcommand{\scrE}{\mathcal{E}}
\newcommand{\scrF}{\mathcal{F}}
\newcommand{\scrG}{\mathcal{G}}
\newcommand{\scrH}{\mathcal{H}}
\newcommand{\scrI}{\mathcal{I}}
\newcommand{\scrJ}{\mathcal{J}}
\newcommand{\scrK}{\mathcal{K}}
\newcommand{\scrL}{\mathcal{L}}
\newcommand{\scrM}{\mathcal{M}}
\newcommand{\scrN}{\mathcal{N}}
\newcommand{\scrO}{\mathcal{O}}
\newcommand{\scrP}{\mathcal{P}}
\newcommand{\scrQ}{\mathcal{Q}}
\newcommand{\scrR}{\mathcal{R}}
\newcommand{\scrS}{\mathcal{S}}
\newcommand{\scrT}{\mathcal{T}}
\newcommand{\scrU}{\mathcal{U}}
\newcommand{\scrV}{\mathcal{V}}
\newcommand{\scrW}{\mathcal{W}}
\newcommand{\scrX}{\mathcal{X}}
\newcommand{\scrY}{\mathcal{Y}}
\newcommand{\scrZ}{\mathcal{Z}}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\colorcomment}[2]{\textcolor{#1}{#2}} %First of these leaves in comments. Second one kills them.
%\newcommand{\colorcomment}[2]{}


\pagestyle{fancy}
\lhead{Max Jeter}
\rhead{MA544, Assignment 3, Page \thepage}

\begin{document}

I don't know if we covered the $\rh$ metric ($\rh(f,g) = \sup(\absval{f(x)-g(x)}: x \in X)$, where $X$ is the domain of $f$ and $g$), but I'm using it because it's nice and I like it.

{\bf Problem 1:}

Consider the sequence of functions $f_n:\R \to \R $ given by $ f_n(x) =x + 1/n$.

It is rather clear that this sequence of functions converges uniformly (to $x$).

However, the sequence of functions $\anbrack{f_n^2}$ fails to converve uniformly:

\tab For each $n \in \N$, $f_n^2(x) = x^2 + 2x/n + 1/n^2$. It is rather clear that $\anbrack{f_n^2}$ converges pointwise to $x^2$. So if $\anbrack{f_n^2}$ converges uniformly to something, it must converge uniformly to $x^2$. However, $\anbrack{f_n^2}$ does not converge uniformly to $x^2$:

\tab \tab Let $\ep >0$, and pick $n \in \N$. Consider $\absval{f_n^2(x)- x^2} = \absval{2x/n + 1/n^2}$. Pick $x = n \ep$. Then $\absval{2x/n + 1/n^2} = 2\ep + 1/n^2 \geq \ep$.

\tab \tab So for all $\ep > 0$ and $n \in \N$ there is an $x \in \R$ such that $\absval{f_n^2(x) - x^2} \geq \ep$; $f_n^2$ does not converge uniformly to $x^2$.

So $\anbrack{f_n}$ converges uniformly on $\R$, but $\anbrack{f_n^2}$ doesn't. This satisfies the problem.

\shunt

{\bf Problem 2:}

\underline{Longish note:} After finishing this problem, I noticed that this follows immediately from a fragment of the proof of Arzela-Ascoli. I prefer this proof, as it is smoother, but it is important to note that such a thing is possible. Moreover, I used a general metric in this one, because it seems like if we had an appropriate extension of Arzela-Ascoli, then this proof could be extended to other types of metric spaces...Does such a theorem exist?

\underline{Proof starts here:} Let $\anbrack{f_n}$ be an equicontinuous sequence of functions on a compact set, $K$, with $\anbrack{f_n}$ converging pointwise to some function, say $f$.

By the Arzela-Ascoli theorem, we know that $\anbrack{f_n}$ has some subsequence that uniformly converges to some function. We know that this function must be $f$: if a subsequence of functions converges uniformly to $f$, it converges pointwise to $f$. If a sequence of functions converges pointwise to a function, $f$, then all of its subsequences converge to $f$. So if a sequence of functions converges pointwise to $f$, then any subsequence of functions that converges uniformly to a function must converge uniformly to $f$.

Now, consider such a converging subsequence, $\anbrack{f_{n_j}}$.

\tab Let $\ep >0$. There is a $J \in \N$ such that for all $j \geq J$, $\rh(f_{n_j}, f) < \ep/4$.

\tab In addition, by equicontinuity, there is a $\de_1 >0$ such that for all $n \in \N$, $x,y \in K$, $d(x,y) < \de_1$ implies that $d(f_n(x),f_n(y)) < \ep/4$.

\tab Moreover, we know that converging sequences of continuous functions converge to continuous functions. We also know that continuous functions on a compact domain are uniformly continuous. Thus, $f$ is uniformly continuous; there is a $\de_2 >0$ such that for all $n \in \N$, $x,y \in K$, $d(x,y) < \de_2$ implies that $d(f(x),f(y)) < \ep/4$.

\tab Define $\de = \min(\de_1,\de_2)$, so that we have both of the lines for $\de$.

\tab We know that compact sets are totally bounded. (If this is not clear, consider a career in pastry making.)

\tab So, let $F$ be a finite collection of points of $K$ such that for all $x \in K$, $d(x,y) < \de$ for some $y \in F$.

\tab Now, for each $y \in F$, there is an $N_y \in \N$ such that for all $n \geq N_y$, $d(f_n(y),f(y)) < \ep/4$. 

\tab Define $N = \max(N_y,n_J)$. 

\tab Now, for all $n \geq N$, and for all $x \in K$, we have, for some $y \in F$ (we pick $y$ with $d(x,y) < \de$: 

\begin{align*}
d(f_n(x),f(x)) &\leq d(f_n(x),f_n(y)) + d(f_n(y),f_{n_j}(y)) + d(f_{n_j}(y), f(y)) + d(f(y),f(x)) \\
&\leq \ep \text{ (That's good enough.)}
\end{align*}

So for all $\ep >0$ there is an $N \in \N$ such that for all $n \geq N$, for all $x \in K$, $d(f_n(x),f(x)) < \ep$. That is, $f_n$ converges uniformly to $f$.

To summarize, if $\anbrack{f_n}$ is an equicontinuous sequence of functions on a compact set, $K$, with $\anbrack{f_n}$ converging pointwise, then $\anbrack{f_n}$ converges uniformly.

\shunt

{\bf Problem 3:}

Let $\anbrack{f_n}$ be a uniformly bounded sequence of functions that are Riemann-integrable on $[a,b]$. Set

\begin{displaymath}
F_n(x) = \int\limits_a^x f_n(t)dt
\end{displaymath}

Moreover, let $L$ be the absolute value of a lower bound for the $f_n$s and let $U$ be the absolute value of an upper bound for the $f_n$s. (I say absolute values here because I don't want to bother with them later.)

Now, the set of $F_n$s are equicontinuous:

\tab Let $\ep >0$. Define $\de = \ep /\max(U,L)$. Then for all $n \in \N$, $x, y \in [a,b]$ with $\absval{x-y} < \de$ (WLOG, $x \leq y$), we have:

\begin{align*}
\absval{F_n(x)-F_n(y)} &= \absval{\int\limits_a^x f_n(t)dt - \int\limits_a^y f_n(t)dt} \\
&= \absval{\int\limits_x^y f_n(t)dt} \text{ I exploit the absolute value here too.} \\
&\leq \absval{(x-y)\max(U,L)} \text{ This is some sort of obvious property of integrals we should know} \\
&< \ep
\end{align*}

\tab So for all $\ep>0$ there is a $\de >0$ such that for all $n \in \N$, $x,y \in [a,b]$, $\absval{x-y} < \de$ implies that $\absval{F_n(x)-F_n(y)} < \ep$. That is, the set of $F_n$s are equicontinuous.

In addition, the $F_n$s are defined on $[a,b]$, which is a compact space. By Arzela-Ascoli, there is a subsequence $\anbrack{F_{n_j}}$ that converges uniformly on $[a,b]$.

\shunt

{\bf Problem 4:}

Let $\anbrack{f_n}$ be a sequence of increasing functions on $\R$ with $0 \leq f_n(x) \leq 1$. 

Some subsequence, $\anbrack{f_{n_k}}$, converges at all rational points, to some function $f$ on the rationals.

\tab Enumerate the rationals.

%Enumerate the rationals, build $f_1$ as the first element that works for the first one, $f_2$ as the second element that works for the first and second, $f_3$ as the third element that works for the first, second, and third, and so on.

Now, define $f(x) = \sup(f(r): r \leq x)$.

Then $f_{n_k}(x) \to f(x)$ at all points of continuity, $x$;

\tab %Proof

Now, there are countably many points of discontinuity of $f$; $f$ is a limit of increasing functions, it must also be increasing, and thus $f$ has countably many points of discontinuity.

Thus, there is a subsequence of $\anbrack{f_{n_k}}$ that converges to $f$ at every point of discontinuity of $f$; %Use the same argument as earlier.

So, this subsequence converges pointwise to $f$ at every point of $\R$, satisfying the problem. 

\shunt

{\bf Problem 5:}

Let $\al$ be increasing on $[a,b]$, $g$ continous, and $g(x) = G'(x)$ for all $x \in [a,b]$.

Then note that both $\int\limits_a^b \al(x)g(x)dx$ and $\int\limits_a^b Gd\al$ exist; the first because it's a product of Riemann-Integrable functions, and the second because $G$ is differentiable, thus continuous, thus $G \in \scrR(\al)$.

Let $\ep >0$. There is a $\de >0$ such that if the mesh of a partition, $P$ of $[a,b]$, is less than $\de$, then for any set of tags of that partition, $T$,

\begin{align*}
\absval{\sum\limits_{i=1}^n g(t_i)\al(x_i) \Delta x_i - \sum\limits_{i=1}^n g(t_i)\al(t_i) \Delta x_i} &< \ep/3 \\
\absval{\sum\limits_{i=1}^n g(t_i)\al(t_i) \Delta x_i - \int\limits_a^b \al(x)g(x)dx} &< \ep/3 \\
\absval{\sum\limits_{i=1}^n G(t_i)\Delta \al_i - \int\limits_a^b G(x)d\al} &< \ep/3 \\
\absval{\sum\limits_{i=1}^n g(t_i)\al(x_i) \Delta x_i - \int\limits_a^b \al(x)g(x)dx} &< 2\ep/3
\end{align*}

The first is because $\al$ is increasing; it has only countably many discontinuities, all of which are jump discontinuities. So, the diference of each $\al(x_i)$ and $\al(t_i)$ can be shrunk by making the difference of $x_i$ and $t_i$ small...which yields the result. The second and third are because either it is the definition of the integral or it is a theorem we should know about integrals. (It depends on the approach, and I'm not sure which one we're taking.) The last is a combination of the first two.

Now, pick a set of tags, $t_i \in [x_{i-1},x_i]$ such that $G(x_i) - G(x_{i-1}) = g(t_i)\De x_i$. We can do this, because of the mean value theorem.

Note that we have the following:

\begin{align*}
\sum\limits_{i=1}^n g(t_i)\al(x_i) \Delta x_i + \sum\limits_{i=1}^n G(x_{i-1})\Delta \al_i &= \sum\limits_{i=1}^n (G(x_i)-G(x_{i-1})) \al(x_i) + G(x_{i-1}) \De \al_i \\
&= \sum\limits_{i=1}^n (G(x_i)-G(x_{i-1}))\al(x_i) + G(x_{i-1})(\al(x_i)-\al(x_{i-1})) \\
&= \sum\limits_{i=1}^n G(x_i)\al(x_i)-G(x_{i-1})\al(x_i) \\
& \tab \tab \tab + G(x_{i-1})\al(x_i)-G(x_{i-1})\al(x_{i-1})) \\
&= \sum\limits_{i=1}^n G(x_i)\al(x_i)-G(x_{i-1})\al(x_{i-1}) \\
&= G(b)\al(b) - G(a)\al(a) \text{ (That's a telescoping sum.)}
\end{align*}

Next,

\begin{align*}
&\absval{G(b)\al(b)-G(a)\al(a)- \int\limits_a^b G(x)d\al - \int\limits_a^b \al(x)g(x)dx} \\
=& \absval{\sum\limits_{i=1}^n g(t_i)\al(x_i) \Delta x_i + \sum\limits_{i=1}^n G(t_i)\Delta \al_i - \int\limits_a^b G(x)d\al - \int\limits_a^b \al(x)g(x)dx} \\
<& \ep
\end{align*}

So for all $\ep >0$, $\absval{G(b)\al(b)-G(a)\al(a)- \int\limits_a^b G(x)d\al - \int\limits_a^b \al(x)g(x)dx} < \ep$. That is, $G(b)\al(b)-G(a)\al(a) =  \int\limits_a^b G(x)d\al + \int\limits_a^b \al(x)g(x)dx$, which is the result.

\shunt

{\bf Problem 6:}

Let $\al$ be an increasing function on $[a,b]$, and for $u \in \scrR (\al)$, define

\begin{align*}
\norm{u}_2 = \left(\int\limits_a^b \absval{u}^2 d\al \right)^{1/2}.
\end{align*}

First, we show that $\int\limits_a^b \absval{fg} \leq \int\limits_a^b \absval{f} \int\limits_a^b \absval{g}$.

\tab %Pull it from Rudin, 1.35

Let $f,g,h \in \scrR(\al)$.

Then we have the following:

\begin{align*}
\int\limits_a^b \absval{f-h}^2 d\al &= \int\limits_a^b \absval{f-g+g-h}^2 d\al \\
&= \int\limits_a^b \absval{f-g+g-h}\absval{f-g+g-h} d\al \\
&\leq \int\limits_a^b \absval{f-g}^2 +2\absval{f-g}\absval{g-h} + \absval{g-h}^2 d\al \\
&= \left(\int\limits_a^b \absval{f-g} d\al + \int\limits_a^b \absval{g-h} d\al\right)^2
\end{align*}

Taking square roots of both sides yields the triangle inequality for this $\cancel{\text{norm}}$ strange function I have never seen before.

\shunt

\end{document}