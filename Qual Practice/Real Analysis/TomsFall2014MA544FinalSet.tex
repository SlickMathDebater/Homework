
\documentclass[a4paper,12pt]{article}

\usepackage{fancyhdr}
\usepackage{amssymb}
%\usepackage{mathpazo}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{slashed}
\usepackage{cancel}
\usepackage[mathscr]{euscript}
\usepackage{MaxPackage} %Note: You need MaxPackage installed or in the same folder as your .tex file or something.

\newcommand{\colorcomment}[2]{\textcolor{#1}{#2}} %First of these leaves in comments. Second one kills them.
%\newcommand{\colorcomment}[2]{}


\pagestyle{fancy}
\lhead{Max Jeter}
\chead{MA544}
\rhead{Practice Set, Page \thepage}

\begin{document}

%This is an attempt at a rough working-through of some problems from Royden's Real Analysis (3rd ed.) textbook.
%Ch. 3: 4 7 8 11 12 14 17 22 23 28 31
%Ch. 4: 2 8 14 15 16 22 25
%Ch. 5: 4 5 8 10 14 16 20 23 27
%Ch. 6: 2 4 8 10 11 15 18 23 24
%Ch. 11: 2 5 7 10 11 13 21 24 25 28 30 33 34 39 41 44 47
%Ch. 12: 1 4 8

%Currently skipped: 
%Ch 3; 28, 31, 
%Ch 4; 25, 
%Ch 5; 14c, 16c, 20c, 23b, 27
%Ch 6; 23
%Ch11;

{\Huge{\textit{\textbf{Chapter 3:}}}}

\shunt

{\bf Problem 4:}

Let $m^*(E) = \infty$ for an infinite set and $m^*(E) = \absval{E}$ for a finite set.

It's clear that $m^*$ is defined for all sets of real numbers, is translation invariant, and countably additive. So $m^*$ is a measure; we call it the counting measure.

\shunt

{\bf Problem 7:}

If $m^*(E)$ is the Lebesgue Outer Measure, it's somewhat clear that it's translation invariant; we can do this by making an open cover and shifting it.

\shunt

{\bf Problem 8:}

If $m^*(A) = 0$, then $m^*(A \cup B) \geq m^*(B)$, by monotonicity.

But also, $m^*(A \cup B) \leq m^*(A) + m^*(B) = m^*(B)$ by countable subadditivity. 

So $m^*(A \cup B) = m^*(B)$.

\shunt

{\bf Problem 11:}

Each $(a, \infty)$ is measurable.

We have $\bigcap\limits^\infty (n, \infty) = \emptyset$ which has measure $0$, but $m((n, \infty)) \to \infty$. So $m(\bigcap\limits^n E_i) \slashed{\to} m(\bigcap\limits^\infty E_n)$

\shunt

{\bf Problem 12:}

Let $\anbrack{E_i}$ be a sequence of disjoint measurable sets, and $A$ be a set.

Then $m^*(A \cap \bigcup\limits^n E_i) = \sum\limits^n m^*(A \cap E_i)$.

So $m^*(A \cap \bigcup\limits^\infty E_i) \geq \sum\limits^n m^*(A \cap E_i)$.

But $n$ is arbitrary, so $m^*(A \cap \bigcup\limits^\infty E_i) \geq \sum\limits^\infty m^*(A \cap E_i)$.

Either by employing a similar argument or appealing to countable subadditivity, we get $m^*(A \cap \bigcup\limits^\infty E_i) = \sum\limits^\infty m^*(A \cap E_i)$.

\shunt

{\bf Problem 14:}

Part a:

The Cantor set has measure zero; it's usually defined as

\begin{displaymath}
[0,1] \setminus ((1/3,2/3) \cup ((1/9,2/9) \cup (7/9,8/9)) \cup \ldots)
\end{displaymath}

Now, $[0,1]$ has measure $1$, and is measurable.

Also, $((1/3,2/3) \cup ((1/9,2/9) \cup (7/9,8/9)) \cup \ldots)$ has measure $1$ (consider the geometric series $1/3, 2(1/3)^2 \ldots$. It sums up to $1$).

So the measure of the cantor set is $1-1=0$.

\shunt

Part b:

If we only remove $\al 3^-n$ at each step when we define the cantor set, then we can show that it would still be closed (as a complement in $[0,1]$ of an open set) and by employing the same geometric series argument, it would have measure $1-\al$.

\shunt

{\bf Problem 17:}

Part a:

Consider the $P_i$s as defined in this section. We're given that $m[0,1) = \sum m^*P_i = \sum m^*P$, so that the right hand side is either zero or infinite. But if it was zero, then we break countable subadditivity; it must be infinite. So we have an example where $m(\bigcup E_i) \leq \sum m^*(E_i)$.

\shunt

Part b:

Define $E_0 = [0,1) \setminus P_0$ and $E_n = [0,1) \setminus P_n$ to get the desired result.

\shunt

{\bf Problem 22:}

Part a:

If $f$ is measurable, then the restriction of $f$ to any measurable set is measurable. If $D_1$ isn't measurable, then the interesection of all of the $\{x: f(x) \geq n\}$ isn't measurable, which is bad. Similarly, $D_2$ must be measurable.

Now, if all of $D_1$, $D_2$ and the restriction of $f$ to $D \setminus D_1 \cup D_2$ are measurable, then for each $\al$ we get $\{x: f(x) \geq \al\}$ the union of $D_1$ and a measurable set, so we win.

\shunt

Part b:

Apply the same trick as used earlier this chapter; prove that if $f$ and $g$  measurable, then so is $f^2$ and $f+g$, and win using $fg= 1/2[(f+g)^2 -f^2-g^2]$. 

\shunt

Parts c and d are painfully trivial.

{\bf Problem 23:}

This was a homework problem; just go there.

\shunt

{\bf Problem 28:}

I'm not sure how to do this one.

\shunt

{\bf Problem 31:}

Not sure how to do this one either. It looks like a very likely qual problem, too...:/

\pagebreak

{\Huge{\textit{\textbf{Chapter 4:}}}}

\shunt

{\bf Problem 2:}

Part a: Let $f$ be a bounded function on $[a,b]$ and let $h$ be the upper envelope of $f$ (that is, $h(x) = \inf\limits_{\de>0} \sup\limits_{\absval{x-y}< \de}(f(y))$)

Then $U-\int\limits_a^b f \geq \int\limits_a^b h$; let $\phi$ be a step function with $\phi \geq f$. Then $\phi \geq h$ except at a finite number of points, because step functions are discontinuous on only finitely many points and the upper envelope is lower than any continuous function above $f$.

Also, $U-\int\limits_a^b f \leq \int\limits_a^b h$; there's a sequence of step functions converging downwards to $h$, so by bounded convergence, we have our result.

So $U-\int\limits_a^b f = \int\limits_a^b h$.

\shunt

Part b:

We get a similar result for the lower envelope. So a bounded function on $[a,b]$ is Riemann-integrable if and only if the integrals of its upper and lower envelopes are equal.

If the upper and lower envelopes are unequal on a set of greater than measure zero, this fails, as the lower envelope is always lower than the upper envelope.

If the upper and lower envelopes are equal except on a set of measure zero, this succeeds, rather obviously.

So a bounded function on $[a,b]$ is Riemann-integrable if and only if the upper and lower envelopes are equal except on a set of measure zero. That is, a bounded function on $[a,b]$ is Riemann-integrable if and only if the function is continuous except on a set of measure zero.

\shunt

{\bf Problem 8:}

Let $\anbrack{f_n}$ be a sequence of nonnegative functions on a domain, $E$. Define $f(x) = \liminf f_n(x)$.

Let $h \leq f$ be any non-negative, simple function with finite measure support on the domain (say it has finite measure support on $F$. 

Then define $h_n = \min(h,f_n)$.

Now, $\int\limits_E h \leq \int\limits_F h= \lim \int\limits_F h_n \leq \liminf \int\limits_E f_n$.

By taking supremums over $h$, we have our result.

\shunt

{\bf Problem 14:}

NOTE: a similar problem was an exam problem. This problem can be generalized, and should be done in the context of $L^p$ spaces.

Part a:

Let $\anbrack{g_n} \to g$ almost everywhere, $\anbrack{f_n} \to f$ almost everywhere, and $\absval{f_n} \leq g_n$, with all of the above functions being measurable, and $\int g = \lim \int g_n$.

Then $\absval{f_n - f} \to 0$ almost everywhere, and $\absval{f_n-f} < g_n+g$. So by applying dominated convergence theorem, we have our result.

\shunt

Part b: 

Let $\anbrack{f_n}$ be a sequence of integrable functions in $L^p$ with $f_n \to f$ almost everywhere.

If $\norm{f_n} \slashed{\to} \norm{f}$, then there's an $\ep >0$ and a subsequence $f_{n_k}$ with $\absval{\norm{f_{n_k}} - \norm{f}} \geq \ep$. But

\begin{align*}
\norm{f_n - f} &\geq \absval{\norm{f_n} - \norm{f}}\\
&\slashed{\to} 0
\end{align*}

If $\norm{f_n} \to \norm{f}$, then a modification of part a applies. So we have our result.

So $\norm{f_n - f} \to 0$ if and only if $\norm{f_n} \to \norm{f}$.

\shunt

{\bf Problem 15:}

The entire problem is ``Apply Littlewood's Three Principles'' and the ``$2^{-n}\ep$ trick''. (On $[-1,1]$ there is a (property) function such that $\absval{f-\phi_1} < 2^{-1}\ep/2$... similarly, there is such a function on $[-2,-1)$ and $(1,2]$ such that $\absval{f-\phi_2} < 2^{-2}\ep/2$...induct, paste everything together, integrate, geometric series, win.)

\shunt

{\bf Problem 16:} NOTE: this was an exam problem.

First, note that if we have that this is true for all step functions vanishing except on a vinite interval, then we have our result; if $\lim\limits_{n \to \infty} cos(nx)\phi(x) dx = 0$ for all such step functions $\phi$, then because there's such a step function with $\int\absval{f - \phi} < \ep$ for all $\ep>0$, we have our result.

So, let $\phi$ be a step function on $[a,b]$, and let $\ep>0$. Partition $[a,b]$ by $a = x_0 < x_1 \ldots x_l = b$ so that $\phi$ is constant on each $(x_i,x_i+1)$. Let $M$ be the maximum of $\absval{\phi}$ (which exists, as $\phi$ takes only finitely many values). Pick $n$ large enough so that $2\pi / n < \ep /(lM)$. Integrate over each chunk of the partition; we end up with everything cancelling out except on sets of length less than $2\pi/n$. There's at most $l$ of them, having magnitude at most $M$; we've won.

\shunt

{\bf Problem 22:}

Note: This problem is lol.

Let there be a sequence, $\anbrack{f_n}$, of measurable functions on a set, $E$, of finte measure, with $f_n \to f$ in measure.

Then every subsequence of $f_n$ converges to $f$ in measure, so every subsequence has a subsequence converging to $f$ in measure.

Now, let there be a sequence, $\anbrack{f_n}$, of measurable functions on a set, $E$, of finte measure, with every subsequence of $f_n$ having a subsequence converging to $f$ in measure.  Then every subsequence of $f_n$ has a  subsequence which has every subsequence have a subsequence that converges almost everywhere to $f$. Thus, every subsequence of $f_n$ has a subsequence that converges almost everywhere to $f$. So $f_n$ converges to $f$ in measure.

\shunt

{\bf Problem 25:}

...Seriously, the hint gives this entire question away. Pretty lame stuff, bro.

\pagebreak

{\Huge{\textit{\textbf{Chapter 5:}}}}

\shunt

{\bf Problem 4:}

Let $f$ be continuous on $[a,b]$ and one of its derivates is everywhere nonnegative on $(a,b)$. Then $D^+$ or $D^-$ is everywhere nonnegative on $(a,b)$; $D^+ \geq D_+$, and $D^- \geq D_-$.

We proceed by handling this for $D^+$, and note that the proof for $D^-$ is similar.

First, if $D^+ \geq \ep >0$ on $(a,b)$, then $\limsup\limits_{h \to 0^+} \frac{f(x+h)-f(x)}{h} \geq \ep$ for all $x$. If for any $x$ there's an $h$ such that $f(x+h) -f(x) < \ep$, then we can apply the sup method to find a contradiction (there should be a least possible $h$ so that we have this property, but this breaks down pretty quickly). 

Now, consider $g_\ep(x) = f(x) + \ep x$. Each $g_\ep$ is increasing, by the above thing. Now, $f = \lim\limits_{\ep \to 0} g_\ep$. So $f$ is a limit of increasing functions, it's increasing.

\shunt

{\bf Problem 5/8:}

5 is a mostly trivial epsilon-delta proof. Note: for part c, it's better to work from the right hand side than the left hand side.

8 is painfully clear.

\shunt

{\bf Problem 10:}

Note: I could've sworn one of these wasn't of bounded variation...

Part a:

(Note: we can restrict our attention to $[0,1]$, rather clearly.)

Consider $f(x) = x^2\sin(1/x^2)$ on $[0,1]$ (with $f(0)=0$).

This is decreasing when $1/x^2 \in [(4n+1)\pi/2,(4n+3)\pi/2]$ for some $n \in \N$.

So it's decreasing when $x^2 \in [2/((4n+3)\pi),2/((4n+1)\pi)]$ for each $n \in \N$. So its negative variance is $\sum\limits_{i=0}^\infty 2/((4n+1)\pi) - 2/((4n+3)\pi) = \sum\limits_{i=0}^\infty 4/pi [1/(4n+1)(4n+3)]$. This sum converges, so the negative variance is finite. Similarly, the positive variance is finite. So the total variance is finite, the function is of bounded variation.

\shunt

Part b:

Consider $f(x) = x^2\sin(1/x)$ on $[0,1]$ (with $f(0)=0$).

This is decreasing when $1/x \in [(4n+1)\pi/2,(4n+3)\pi/2]$ for some $n \in \N$.

So it's decreasing when $x \in [2/((4n+3)\pi),2/((4n+1)\pi)]$ for each $n \in \N$. So its negative variance is $\sum\limits_{i=0}^\infty (2/((4n+1)\pi))^2 - (2/((4n+3)\pi))^2$, which converges. So the total variance is finite, the function is of bounded variation.

\shunt

{\bf Problem 14:}

Part a:

Sums and differences of two absolutely continuous functions are also absolutely continous, rather clearly. (If $\ep >0$, use $\de = \max(de_1,\de_2)$, with $\de_1$ working for $\ep/2$ for one function and $\de_2$ working for $\ep/2$ with the other function.)

\shunt

Part b:

Products of two absolutely continuous functions are absolutely continuous; the domain is necessarily a closed interval, continuous functions on closed intervals are bounded. Pick one function; it is absolutely bounded by $M$. For the other function, for all $\ep >0$ there's a $\de >0$ that works for $\ep/M$. Use this $\de$.

\shunt

Part c:

I'm absolutely stuck on this one.

\shunt

{\bf Problem 16:}

Part a:

Let $f$ be a monotone increasing function. Then $f'$ exists almost everywhere; Let $f_c$ be the indefinite integral of $f'$, so that $f_c$ is absolutely continuous. Then $f_s=f-f_c$ has derivative zero almost everywhere. That is, $f=f_s+f_c$ is a decomposition of $f$ into a sum of singular and absolutely continuous functions.

\shunt

Part b:

Let $f$ be a nondecreasing singular function on $[a,b]$. Let $\ep>0$, $\de>0$.

First, $f$ is bounded; it is monotonic on a closed interval. Second, $f'$ is zero almost everywhere. That is, there's a collection of nonoverlapping (open) intervals, call it $\scrI$, whose total length is less than $\de$ that covers the set of points where $f'$ is nonzero (or undefined).

That is, $f$ is constant on the entire domain except (possibly) those intervals.

So, we have that $\sum\limits_{I \in \scrI} l(I) < \de$, and $\sum\limits_{I \in \scrI} d(f(I)) = f(b)-f(a)$, where $d(f(I))$ is the distance between the endpoints of $f(I)$. (We have the second part, as $f$ is constant except on intervals in $\scrI$.)

Thus, $\sum\limits_{I \in \scrI} d(f(I)) = f(b)-f(a)$ converges upwards to $f(b)-f(a)$; there's a finite collection of intervals in $\scrI$ (call it $\scrF$) with $\sum\limits_{I \in \scrF} d(f(I)) + \ep = f(b) -f(a)$. This satisfies the problem. (We summarize this result as ``nondecreasing singular functions have property $(S)$'').

\shunt

Part c:

Let $f$ be a nondecreasing function on $[a,b]$ with property $(S)$. Then $f=f_s+f_c$ for some singular $f_s$ and absolutely continuous $f_c$. Moreover, we can take both $f_c$ and $f_s$ nondecreasing.

Now, let $\ep>0$. There's a $\de>0$ with the property $\sum \absval{x_i-x_{i+1}} < \de$ implies that $\sum \absval{f_c(x_i)-f_c(x_{i+1})} < \ep$ for any non-overlapping, finite collection of intervals $(x_i,x_{i+1})$. Also, there's a finite collection of such intervals with the property $\sum \absval{f(x_i)-f(x_{i+1})} +\ep > f(b)-f(a)$, for any $/ep>0$. %I'm not sure how to play this out, but this is somewhat obviously the right course of action.

\shunt

Part d:

Let $\anbrack{f_n}$ be a sequence of nondecreasing singular functions on $[a,b]$ with $f = \sum f_n(x)$ everywhere finite.

Then $f$ is singular, by term-by-term differentiation.

\shunt

Part e:

A series of indicator functions of the form $\chi_{[q,1]}$ with $q \in \Q$ cobbled together with the $2^{-n}$ trick suffices. (Enumerate the rationals, sum them up.)

\shunt

{\bf Problem 20:}

Part a: is a simple epsilon-delta proof.

\shunt

Part b:

Let $f$ be absolutely continuous.

Then if $f$ fails to satisfy a Lipschitz condition, there is a pair of sequences $x_n,y_n$ that break the Lipschitz condition. As $f$ is absolutely continuous, such a subsequence must exist with $d(x_n,y_n) \to 0$; this is because $f$ is bounded. So we can find a sequence of pairs of points arbitrarily close together whose difference quotient is arbitrarily large; the derivative thus cannot be bounded.

If $f$ satisfies a Lipschitz condition, then the difference quotient is uniformly bounded at all points; so the limits of these difference quotients are uniformly bounded, so the derivative is bounded.

\shunt

Part c:

If one of the derivates of a function is bounded, say $D+$, then...

\shunt

{\bf Problem 23:}

Part a:

Let $\phi$ be a convex function on a finite interval, $[a,b)$.

Let $\phi$ not be bounded below. Because $\phi$ is absolutely continuous on each closed subinterval of $[a,b)$, this means that $\phi$ is bounded on each closed subinterval of $[a,b)$. Thus, if $\phi$ is not bounded below, then we have that $\lim\limits_{x \to b} \phi(x) = -\infty$ (else, $\phi$ can be extended to $[a,b]$, and is thus bounded).

But this goes bad pretty quickly (Pick a point on the curve, draw a chord from $(a, \phi(a))$, make it have arbitrarily negative slope, it'll go below that point eventually.)

\shunt

Part b:

\shunt

Part c is trivial

\shunt

{\bf Problem 27:}

I've spent way too long on this problem. It's similar to a problem in Zigmund's book, apparently...

\pagebreak

{\Huge{\textit{\textbf{Chapter 6:}}}}

\shunt

{\bf Problem 2:}

Let $f \in L^\infty[0,1]$. Define $\norm{f}_\infty = M$. Then for all $p$, $\norm{f}_p/M = \norm{f/M}_p$. It suffices to show that $\lim\limits_{p \to \infty} \norm{f/M}_p = 1$.

Now, for all $p>0$, we have that $[\int \absval{f/M}^p]^{1/p} \leq [\int \absval{f/M}]^{1/p} \leq 1^{1/p} = 1$. So the limit as $p$ tends to infinity is bounded above by $1$. 

Next, let $\ep \in (0,1]$. Then because the essential supremum of $f/M$ is $1$, there's a set, $E$, of measure $\de>0$ with the property $x \in E$ implies that $f(x) \geq \absval{1-\ep/2}$. Now,

\begin{align*}
[\int \absval{f/M}^p]^{1/p} &\geq [\int_E \absval{f/M}^p]^{1/p}\\
&\geq [\int_E (1-\ep/2)^p]^{1/p}\\
&= [(1-\ep/2)^p m(E)]^{1/p}\\
&= (1-\ep/2)m(E)^{1/p}
\end{align*}

By taking $p$ sufficiently large, we have this greater than $1-\ep$. 

So we have our result.

\shunt

{\bf Problem 4:}

Let $f \in L^1$, $g \in L^\infty$. Define $M = \norm{g}_\infty$.

\begin{align*}
\int\absval{fg/M}  &\leq \int \absval{f}\\
&= \norm{f}_1
\end{align*}

So,

\begin{align*}
\int\absval{fg}  &\leq M\norm{f}_1 = \norm{f}_1\norm{g}_\infty
\end{align*}
\shunt

{\bf Problem 8:}

This was effectively done in your homework.

\shunt

{\bf Problem 10:}

Note: This is effectively saying that the norm on $L^\infty$ is the norm induced by the metric of uniform convergence. This is probably given outright in Pugh.

Let $\anbrack{f_n}$ be a sequence of functions in $L^\infty$.

Let there fail to be a set, $E$, of measure $0$ such that $f_n$ converges to $f$ uniformly on $E^c$. That is, there's a set of nonzero measure such that $f_n$ fails to converge to $f$ uniformly on $E$. Then there's an $\ep>0$ and a subsequence of $f_n$ with the property $\norm{f_{n_k} - f}_\infty \geq \ep$ on a set of greater than measure zero. That is, there's a subsequence of $f_n$ such that $\norm{f_{n_k}-f}_\infty \geq \ep$; $f_n$ does not converge to $f$ in $L^\infty$. 

If there's a set, $E$, of measure $0$ such that $f_n$ converges to $f$ uniformly on $E^c$, then for all $\ep>0$ there's an $N \in \N$ such that for all $n \geq N$, $\absval{f_n-f} < \ep$ except on $E$. That is, $\norm{f_n-f}_\infty < \ep$. That is, $f_n \to f$ in $L^\infty$.

\shunt

{\bf Problem 11:}

This is pulled straight out of Pugh; if a sequence of functions has cauchy uniform convergence, it has pointwise cauchy convergence, so it has pointwise convergence. This convergence is also uniform, somewhat trivially.

\shunt

{\bf Problem 15:}

Note: this looks like a good qual problem...

Let $c$ be the space of all convergent sequences of real numbers, given the $\ell^\infty$ norm.

First, this is a normed linear space; $\ell^\infty$ norm is a norm, and the space is clearly linear.

Now, let $\anbrack{\anbrack{n_k}}$ be a Cauchy sequence of converging sequences. 

Then for all $\ep>0$, there's an $N$ such that $n,m > N$ implies that for all $k$, $\absval{n_k-m_k} < \ep$. That is, for fixed $k$, $\anbrack{n_k}$ treated as a sequence in $n$ is Cauchy. So each of these converges to something; call it $N_k$. It is rather clear that $\anbrack{n_k} \to \anbrack{N_k}$ as a sequence using the $\ell^\infty$ norm from this.

Now, let $c_0$ be the space of all sequences of real numbers converging to zero. It is also a normed linear space. It's also a closed subset of $c$; if $\anbrack{\anbrack{n_k}} \to \anbrack{a_k}$ with $\anbrack{n_k}$ each in $c_0$, then $a_k \to 0$, this is clear by triangle inequality.

So $c_0$ is a closed subset of a complete normed linear space. It is complete. So $c_0$ is a Banach space.

\shunt

{\bf Problem 18:}

Note: This is very similar to problems given in past quals...

We first note that $f_ng_n \to fg$ almost everywhere, and that this is clear. We proceed by applying the an earlier problem; the result follows if $\norm{f_ng_n}_p \to \norm{fg}_p$.

Somewhat clearly, if the left hand side converges, then it converges to the right hand side. Moreover, the sequence is Cauchy, so it converges. %I'm not sure how to handle that, but that seems to be the idea.

\shunt

{\bf Problem 23:}

This problem is made of nope and nope.

\shunt

{\bf Problem 24:}

Let $g,h \in L^q$ be such that $\int fg = \int fh$ for all $f \in L^p$. 

Then $\int f(g-h) = 0$ for all $f \in L^p$. So in particular, this is true for all indicator functions on sets of finite length. We can game this so that $\int f(g-h)$ is always positive; $f = 1$ if $g-h$ is positive, and $f=-1$ if $h-g$ is positive works, and is measurable as $h$ and $g$ are. We know that this means that $f(g-h)$ is zero almost everywhere; thus, we get that $g-h$ is zero almost everywhere, so $g$ must have been almost-everywhere-unique.

\shunt

\end{document}